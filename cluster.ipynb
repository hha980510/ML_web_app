{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, HRFlowable\n",
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset file\n",
    "def load_file(file_path):\n",
    "    file_extention = file_path.split('.')[-1]\n",
    "    if file_extention == 'csv':\n",
    "        return pd.read_csv(file_path)\n",
    "    \n",
    "    elif file_extention == 'xlsx':\n",
    "        return pd.read_excel(file_path)\n",
    "    \n",
    "    elif file_extention == 'json':\n",
    "        return pd.read_json(file_path)\n",
    "    \n",
    "    else:\n",
    "        return print(\"Use other file formate, .csv, .xlsx, .json\")\n",
    "\n",
    "# Find the useful variables to cluster\n",
    "def identify_variable(data, threshold):\n",
    "    corr_matrix = data.corr()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "\n",
    "    variables = (upper_triangle[upper_triangle > threshold]).stack().index.tolist()\n",
    "    variables = list(set([item for sublist in variables for item in sublist]))\n",
    "\n",
    "    return variables\n",
    "\n",
    "def preprocessing_data(data):\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "\n",
    "    return scaled_df\n",
    "\n",
    "def perform_pca(data, n_components=None):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    transform_data = pca.fit_transform(data)\n",
    "\n",
    "    return transform_data\n",
    "\n",
    "# Determine optimal number of clusters using elbow method\n",
    "def elbow(data):\n",
    "    wcss = []\n",
    "    for i in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "\n",
    "    # Find the elbow point\n",
    "    x1, y1 = 1, wcss[0]\n",
    "    x2, y2 = len(wcss), wcss[-1]\n",
    "    dis = []\n",
    "    for i in range(1, len(wcss) - 1):\n",
    "        x0 = i + 1\n",
    "        y0 = wcss[i]\n",
    "        numerator = abs((y2 - y1) * x0 - (x2 - x1) * y0 + x2 * y1 - y2 * x1)\n",
    "        denominator = ((y2 - y1) ** 2 + (x2 - x1) ** 2) ** 0.5\n",
    "        dis.append(numerator / denominator)\n",
    "    \n",
    "    elbow_point = dis.index(max(dis)) + 2\n",
    "    \n",
    "    plt.plot(range(1, 11), wcss, marker='o')\n",
    "    plt.axvline(elbow_point, color='b', linestyle='-')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.savefig('./sample_output/_img/Elbow_Method.png')\n",
    "    plt.show()\n",
    "\n",
    "    return elbow_point\n",
    "\n",
    "# Algorithm for choosing the number of clusters. \n",
    "def choose_cluster(elbow, silhouette):\n",
    "    cluster_info = \"\"\n",
    "\n",
    "    # If the values of elbow method and silhouette method are different, \n",
    "    if elbow != silhouette:\n",
    "        cluster_info += f\"Elbow method suggests {elbow} clusters.\\n\"\n",
    "        cluster_info += f\"Silhouette method suggests {silhouette} clusters.\\n\"\n",
    "\n",
    "        if abs(elbow - silhouette) > 1:\n",
    "            cluster_info += \"The difference between the two methods is significant.\\n\"\n",
    "            cluster_info += \"Choosing the number of clusters based on silhouette method.\\n\"\n",
    "            chosen_cluster = silhouette\n",
    "        \n",
    "        else:\n",
    "            cluster_info += \"The difference between the two methods is not significant.\"\n",
    "            cluster_info += \"Choosing the number of clusters based on their average.\"\n",
    "            chosen_cluster = int((elbow + silhouette) / 2)\n",
    "    \n",
    "    else:\n",
    "        cluster_info += f\"Both methods suggest the same number of clusters: {elbow}.\\n\"\n",
    "        chosen_cluster = elbow\n",
    "    \n",
    "    return chosen_cluster, cluster_info\n",
    "\n",
    "# Perform k-Means clustering algorithm\n",
    "def kmeans(data, n_cluster):\n",
    "    kmean = KMeans(n_clusters = n_cluster, random_state=42, n_init='auto')\n",
    "    labels = kmean.fit_predict(data)\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Perform Hierarchical clustering, Agglomerative (aka bottom-up method) algorithm\n",
    "def agglomerative(data, n_cluster):\n",
    "    agg_clustering = AgglomerativeClustering(n_clusters = n_cluster).fit(data)\n",
    "    labels = agg_clustering.labels_\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Choose which clustering algorithm will be run, depend on the user's choice\n",
    "def choose_algo(data, n_cluster, algorithm='both'):\n",
    "    if algorithm == 'k-Means':\n",
    "        return kmeans(data, n_cluster)\n",
    "    \n",
    "    elif algorithm == 'Agglomerative Clustering':\n",
    "        return agglomerative(data, n_cluster)\n",
    "    \n",
    "    else:\n",
    "        return kmeans(data, n_cluster), agglomerative(data, n_cluster)\n",
    "\n",
    "# Generate the cluster plots, depending on the user's choice\n",
    "def plot_cluster(pca_df):\n",
    "    # If user choose both algorithms, plot both\n",
    "    if 'k-Means Cluster' and 'Agglomerative Cluster' in pca_df.columns:\n",
    "        axs_k = plt.subplots()\n",
    "        axs_k = sns.scatterplot(x=pca_df[0], y=pca_df[1], hue='k-Means Cluster', data=pca_df)\n",
    "        plt.title('k-Means Cluster')\n",
    "        plt.savefig('./sample_output/_img/k-Means_Cluster.png')\n",
    "\n",
    "        axs_a = plt.subplots()\n",
    "        axs_a = sns.scatterplot(x=pca_df[0], y=pca_df[1], hue='Agglomerative Cluster', data=pca_df)\n",
    "        plt.title('Agglomerative Cluster')\n",
    "        plt.savefig('./sample_output/_img/Agglomerative_Cluster.png')\n",
    "    \n",
    "    # If user choose only Agglomerative clustering algorithm, then plot agglomerative cluster\n",
    "    elif 'Agglomerative Cluster' in pca_df.columns:\n",
    "        axs = plt.subplots()\n",
    "        axs = sns.scatterplot(x=pca_df[0], y=pca_df[1], hue='Agglomerative Cluster', data=pca_df)\n",
    "        plt.title('Agglomerative Cluster')\n",
    "        plt.savefig('./sample_output/_img/Agglomerative_Cluster.png')\n",
    "    \n",
    "    # If user choose only k-Means clustering algorithm, then plot k-Means cluster\n",
    "    elif 'k-Means Cluster' in pca_df.columns:\n",
    "        axs = plt.subplots()\n",
    "        axs = sns.scatterplot(x=pca_df[0], y=pca_df[1], hue='k-Means Cluster', data=pca_df)\n",
    "        plt.title('k-Means Cluster')\n",
    "        plt.savefig('./sample_output/_img/k-Means_Cluster.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters using silhouette method\n",
    "class silhouetteAnalyze:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.silhouette_scores = None\n",
    "        self.optimal_clusters = None\n",
    "    \n",
    "    def analyze(self):\n",
    "        silhouette_scores = []\n",
    "        for i in range(2, 11):\n",
    "            kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "            cluster_labels = kmeans.fit_predict(self.data)\n",
    "            silhouette_avg = silhouette_score(self.data, cluster_labels)\n",
    "            silhouette_scores.append(silhouette_avg)\n",
    "        \n",
    "        self.silhouette_scores = silhouette_scores\n",
    "    \n",
    "    def get_optimal_clusters(self):\n",
    "        if self.silhouette_scores is None:\n",
    "            print(\"Call analyze() method first to compute silhouette scores.\")\n",
    "            return None\n",
    "\n",
    "        optimal_clusters_index = np.argmax(self.silhouette_scores)\n",
    "        self.optimal_clusters = optimal_clusters_index + 2\n",
    "        return self.optimal_clusters\n",
    "    \n",
    "    def get_silhouette_scores(self):\n",
    "        if self.silhouette_scores is None:\n",
    "            print(\"Call analyze() method first to compute silhouette scores.\")\n",
    "            return None\n",
    "        \n",
    "        return self.silhouette_scores\n",
    "    \n",
    "    def plot(self):\n",
    "        if self.silhouette_scores is None:\n",
    "            print(\"Call analyze() method first to compute silhouette scores.\")\n",
    "            return\n",
    "        \n",
    "        plt.plot(range(2, 11), self.silhouette_scores, marker='o')\n",
    "        plt.axvline(self.optimal_clusters, color='b', linestyle='-')\n",
    "        plt.xlabel('Number of clusters')\n",
    "        plt.ylabel('Silhouette Score')\n",
    "        plt.title('Silhouette Method')\n",
    "        plt.savefig('./sample_output/_img/Silhouette_Method.png')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Main function\n",
    "Constructe the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path, threshold, algorithm, n_components, plot):\n",
    "\n",
    "    # Call the file and save it to a variable, df\n",
    "    df = load_file(file_path)\n",
    "    file_name = Path(file_path).stem\n",
    "    \n",
    "    # Create a PDF document\n",
    "    doc = SimpleDocTemplate(\"./sample_output/_doc/Report.pdf\", pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    title = Paragraph(\"Clustering Report\", styles['Title'])\n",
    "    file_name_para = Paragraph(f\"File Name: {file_name}\", styles['Normal'])\n",
    "\n",
    "    pre_df = preprocessing_data(df)\n",
    "\n",
    "    # Reduce columns with the most relevant columns\n",
    "    variable_names = identify_variable(pre_df, threshold)\n",
    "    filtered_df = pre_df[variable_names]\n",
    "\n",
    "    # Elbow method to determine the number of clusters\n",
    "    elbow_cluster = elbow(filtered_df)\n",
    "\n",
    "    # Silhouette method to determine the number of clusters\n",
    "    silhouette = silhouetteAnalyze(filtered_df)\n",
    "    silhouette.analyze()\n",
    "    silhou_cluster = silhouette.get_optimal_clusters()\n",
    "    silhouette.plot()\n",
    "\n",
    "    n_cluster, cluster_info = choose_cluster(elbow_cluster, silhou_cluster)\n",
    "\n",
    "    cluster = choose_algo(filtered_df, n_cluster, algorithm)\n",
    "    if algorithm == 'both':\n",
    "        kmeans_label, agglom_label = cluster\n",
    "        df['k-Means Cluster'] = kmeans_label\n",
    "        df['Agglomerative Cluster'] = agglom_label\n",
    "\n",
    "    elif algorithm == 'k-Means':\n",
    "        kmeans_label = cluster\n",
    "        df['k-Means Cluster'] = kmeans_label\n",
    "        \n",
    "    else:\n",
    "        agglom_label = cluster\n",
    "        df['Agglomerative Cluster'] = agglom_label\n",
    "\n",
    "    if plot == 'yes':\n",
    "        if n_components == None:\n",
    "            pca = perform_pca(filtered_df, 2)\n",
    "        \n",
    "        else:\n",
    "            pca = perform_pca(filtered_df, n_components)\n",
    "        \n",
    "        pca_df = pd.DataFrame(pca)\n",
    "        pca_df['k-Means Cluster'] = df['k-Means Cluster']\n",
    "        pca_df['Agglomerative Cluster'] = df['Agglomerative Cluster']\n",
    "\n",
    "        plot_cluster(pca_df)\n",
    "\n",
    "        scores = silhouette.get_silhouette_scores()\n",
    "        scores = scores[n_cluster - 2]\n",
    "        \n",
    "        if scores >= 0.5:\n",
    "            score_info = \"Since Silhouette Score is greater than or equal to 0.5, it is STRONG evidence of well-defined clusters.\"\n",
    "        \n",
    "        elif scores < 0.5 and scores >= 0.25:\n",
    "            score_info = \"Since Silhouette Score is in between 0.25 and 0.5, it is MODERATE evidence of well-defined clusters.\"\n",
    "        \n",
    "        elif scores < 0.25 and scores > -0.25:\n",
    "            score_info = \"Since Silhouette Score is in between -0.25 and 0.25, it is WEAK or No structure.\"\n",
    "\n",
    "        elif scores <= -0.25 and scores > -0.5:\n",
    "            score_info = \"Since Silhouette Score is in between -0.5 and -0.25, it May indicate that data points have been assigned to the wrong clusters.\"\n",
    "\n",
    "        elif scores <= -0.5:\n",
    "            score_info = \"Since Silhouette Score is smaller than or eqaul to -0.5, it is Strong evidence of misclassification or poor clustering structure.\"\n",
    "        \n",
    "    silhouette_info = f\"\\nSilhouette Score: {scores}\"\n",
    "\n",
    "    cluster_text = Paragraph(cluster_info, styles['Normal'])\n",
    "    silhouette_text = Paragraph(silhouette_info, styles['Normal'])\n",
    "    score_text = Paragraph(score_info, styles['Normal'])\n",
    "    line = HRFlowable(width=\"100%\", thickness=1, lineCap='square', color=\"black\", spaceBefore=10, spaceAfter=10)\n",
    "\n",
    "\n",
    "    content = [title, Spacer(1, 24), file_name_para, line, cluster_text, silhouette_text, score_text, Spacer(1,12)]\n",
    "\n",
    "    elbow_img = './sample_output/_img/Elbow_Method.png'\n",
    "    if elbow_img:\n",
    "        plot_img = plt.imread(elbow_img)\n",
    "        img_width = 400\n",
    "        img_height = img_width * plot_img.shape[0] / plot_img.shape[1]\n",
    "        elbow_img_obj = Image(elbow_img, width=img_width, height=img_height)\n",
    "        content.append(Spacer(1, 12))\n",
    "        content.append(elbow_img_obj)\n",
    "\n",
    "    silhouette_img = './sample_output/_img/Silhouette_Method.png'\n",
    "    if silhouette_img:\n",
    "        plot_img = plt.imread(silhouette_img)\n",
    "        img_width = 400\n",
    "        img_height = img_width * plot_img.shape[0] / plot_img.shape[1]\n",
    "        silhouette_img_obj = Image(silhouette_img, width=img_width, height=img_height)\n",
    "        content.append(Spacer(1, 12))\n",
    "        content.append(silhouette_img_obj)\n",
    "\n",
    "    kmeans_img = './sample_output/_img/k-Means_Cluster.png'\n",
    "    if kmeans_img:\n",
    "        plot_img = plt.imread(kmeans_img)\n",
    "        img_width = 400\n",
    "        img_height = img_width * plot_img.shape[0] / plot_img.shape[1]\n",
    "        kmeans_img_obj = Image(kmeans_img, width=img_width, height=img_height)\n",
    "        content.append(Spacer(1, 12))\n",
    "        content.append(kmeans_img_obj)\n",
    "\n",
    "    agglom_img = './sample_output/_img/Agglomerative_Cluster.png'\n",
    "    if agglom_img:\n",
    "        plot_img = plt.imread(agglom_img)\n",
    "        img_width = 400\n",
    "        img_height = img_width * plot_img.shape[0] / plot_img.shape[1]\n",
    "        agglom_img_obj = Image(agglom_img, width=img_width, height=img_height)\n",
    "        content.append(Spacer(1, 12))\n",
    "        content.append(agglom_img_obj)\n",
    "    \n",
    "    doc.build(content)\n",
    "    \n",
    "    df.to_csv('./sample_output/_doc/Result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('/Users/namgyulee/Personal_Project/ML_PaaS/data/wine-clustering.csv', 0.5, 'both', 2, 'yes')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38666f145cb64d8d46330446ca9b691a12adce0806ded29f825ff3249b7803fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
